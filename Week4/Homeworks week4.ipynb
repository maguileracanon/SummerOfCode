{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base code for basic data we used during the whole week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements - To keed this in order\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from nltk.corpus import opinion_lexicon\n",
    "import urllib.request, os, gzip\n",
    "import  json\n",
    "import random\n",
    "import numpy # a powerfull module\n",
    "from nltk.corpus import stopwords # We use it to remove the stopwords of the comments since they dont provide relevant info\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize # Divide text in sentences and then in words\n",
    "from sklearn.linear_model import LinearRegression # sklearn is a machine learning toolkit (needs numpy, scipy and matplotlib)\n",
    "from sklearn.linear_model import LogisticRegression # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# If I am not mistaken, logistic regresion is for booleans clasiffiers\n",
    "from  sklearn.metrics import precision_score, recall_score # I think these are metrics to evaluate models form the slklearn library\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB # To apply statistical models, not regressions(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Baby has already been downloaded to ./data/\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "datadir = './data/'\n",
    "\n",
    "def download_data(dataset_name, datadir):\n",
    "    filename = 'reviews_%s_5.json' % dataset_name\n",
    "    filepath = os.path.join(datadir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(\"Dataset %s has already been downloaded to %s\" % (dataset_name, datadir))\n",
    "    else:\n",
    "        url = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/%s.gz' % filename\n",
    "        urllib.request.urlretrieve(url, filepath + \".gz\")\n",
    "        with gzip.open(filepath + \".gz\", 'rb') as fin:\n",
    "            with open(filepath, 'wb') as fout:\n",
    "                fout.write(fin.read())\n",
    "        print(\"Downloaded dataset %s and saved it to %s\" % (dataset_name, datadir))\n",
    "\n",
    "dataset = \"Baby\"\n",
    "download_data(dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 160792 data for dataset Baby\n"
     ]
    }
   ],
   "source": [
    "def  load_data (dataset_name, datadir):\n",
    "    filepath = os.path.join(datadir, 'reviews_%s_5.json' % dataset_name)\n",
    "    if not os.path.exists(filepath):\n",
    "        download_data(dataset_name, datadir)\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:                            # read file line by line\n",
    "            item_hash = hash(line)                # we will use this later for partitioning our data \n",
    "            item = json.loads(line)               # convert JSON string to Python dict\n",
    "            item['hash'] = item_hash              # add hash for identification purposes\n",
    "            data.append(item)\n",
    "    print(\"Loaded %d data for dataset %s\" % (len(data), dataset_name))\n",
    "    return data\n",
    "\n",
    "# load the data...\n",
    "baby = load_data(dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 96291 training examples, 32244 validation examples, and 32257 test examples\n"
     ]
    }
   ],
   "source": [
    "def partition_train_validation_test(data):\n",
    "    # 60% : modulus is 0, 1, 2, 3, 4, or 5\n",
    "    data_train = [item for item in data if item['hash']%10<=5]  \n",
    "    # 20% : modulus is 6 or 7\n",
    "    data_valid = [item for item in data if item['hash']%10 in [6,7]] \n",
    "    # 20% : modulus is 8 or 9\n",
    "    data_test  = [item for item in data if item['hash']%10 in [8,9]] \n",
    "    print(\"Now we have\", len(data_train), \"training examples,\", len(data_valid),\n",
    "      \"validation examples, and\", len(data_test), \"test examples\")\n",
    "    return data_train, data_valid, data_test\n",
    "    \n",
    "baby_train, baby_valid, baby_test = partition_train_validation_test(baby)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8571428571428571, 0.0)\n",
      "(0.0, 0.8571428571428571)\n"
     ]
    }
   ],
   "source": [
    "eng_stopwords = set(stopwords.words('english'))\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "def my_tokenize(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        #Adds to the array and array with the words in lowercase, we add them if they are not stopwords and there is at least one letter in it\n",
    "        tokens.extend(x for x in word_tokenize(sentence.lower()) #continues down...\n",
    "                      if x not in eng_stopwords and any(i.isalpha() for i in x))# This extends the list by adding elements, it is different from append... see https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python \n",
    "    return tokens\n",
    "\n",
    "def pos_neg_fraction(text): # We recieve the raw text\n",
    "    tokens = my_tokenize(text) # We tokenize the text first\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in positive_words:\n",
    "            count_pos += 1\n",
    "        if t in negative_words:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens) # this is because we need to be sure there is no 0 len sentence\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:\n",
    "        return 0., 0.\n",
    "    \n",
    "pos_example = 'This is a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example = 'This is a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction(pos_example))\n",
    "print(pos_neg_fraction(neg_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found a fraction of 100.000000 % positive words for example 10561\n",
      "{'reviewerID': 'A2FPJGVT01TVVQ', 'asin': 'B000A88JYQ', 'reviewerName': 'S. Broderick \"Sondra\"', 'helpful': [0, 0], 'reviewText': 'work perfect', 'overall': 5.0, 'summary': 'Five Stars', 'unixReviewTime': 1404691200, 'reviewTime': '07 7, 2014', 'hash': -8116255050029596758}\n",
      "We found a fraction of 100.000000 % negative words for example 24850\n",
      "{'reviewerID': 'A1SLEYD29KEUW1', 'asin': 'B000WUD83O', 'reviewerName': 'ABDULLAH AL-FALAH', 'helpful': [0, 0], 'reviewText': 'too noisy', 'overall': 2.0, 'summary': 'Two Stars', 'unixReviewTime': 1404432000, 'reviewTime': '07 4, 2014', 'hash': -8656440585229339815}\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_matrix(data):\n",
    "    # data is a lot of text in {} that has reviwer name..comment...date...etc.. but all identified with text labels\n",
    "    #in that sence data is an unidiminsional array\n",
    "    # the item \"atribute\", we added it to the data to identify the sections of it\n",
    "    return numpy.array([list(pos_neg_fraction(item['reviewText'])) for item in data])\n",
    "# X_train with two columns and as many rows as there are examples in the data set. \n",
    "#The first column contains the fraction of positive words, \n",
    "#while the second column contains the fraction of negative words for each example.\n",
    "X_train = dataset_to_matrix(baby_train)\n",
    "most_pos, most_neg = numpy.argmax(X_train, axis=0) # find maximum ROW (axis 0).. through aaaaallll the data (OMG!)\n",
    "# print the example with the highest fraction of positive words:\n",
    "print(\"We found a fraction of %f %% positive words for example %d\" % \n",
    "      (100.*X_train[most_pos, 0], most_pos))\n",
    "print(baby_train[most_pos])\n",
    "print(\"We found a fraction of %f %% negative words for example %d\" %\n",
    "      (100.*X_train[most_neg, 1], most_neg))\n",
    "print(baby_train[most_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our feature matrix is two-dimensional and has shape (96291, 2)\n",
      "Our target vector is one-dimensional and has shape (96291,)\n"
     ]
    }
   ],
   "source": [
    "def  dataset_to_targets (data):\n",
    "    return numpy.array([item['overall'] for item in data])\n",
    "\n",
    "Y_train = dataset_to_targets(baby_train)\n",
    "print(\"Our feature matrix is two-dimensional and has shape\", X_train.shape) # contains pos,neg fraction\n",
    "print(\"Our target vector is one-dimensional and has shape\", Y_train.shape) # containd sscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for the fpos variable is 3.25703026268183\n",
      "The coefficient for the fneg variable is -5.593432938808693\n",
      "The intercept is 4.004491648095601\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression().fit(X_train,Y_train)\n",
    "print(\"The coefficient for the fpos variable is\", lreg.coef_[0])\n",
    "print(\"The coefficient for the fneg variable is\", lreg.coef_[1])\n",
    "print(\"The intercept is\", lreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is 4.655898 stars\n",
      "This is the same as 4.655898 stars\n",
      "The expected rating is 2.885805 stars\n",
      "This is the same as 2.885805 stars\n"
     ]
    }
   ],
   "source": [
    "#If the review contains 20% positive words (fpos==0.2) \n",
    "#but still no negative words (fneg==0), we would expect the following rating:\n",
    "features = [[0.2, 0]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0.2*lreg.coef_[0] + 0*lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)\n",
    "#However, if the review contains no positive words (fpos==0) but 20% negative words (fneg==0.2),\n",
    "#we expect the following rating:\n",
    "features = [[0, 0.2]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0 * lreg.coef_[0] + 0.2 * lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lreg(features):\n",
    "    expected_rating = lreg.predict(features)\n",
    "    expected_rating[expected_rating > 5.0] = 5.0\n",
    "    expected_rating[expected_rating < 1.0] = 1.0\n",
    "    return expected_rating\n",
    "\n",
    "pred_train = predict_lreg(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training data is 0.827639 stars\n"
     ]
    }
   ],
   "source": [
    "mae_train = mean_absolute_error(pred_train, Y_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" % mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - calculate the prediction for 100% pos, and 100% neg review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating for 100 pos review is 7.261522 stars\n",
      "The expected rating  for 100 neg review is -1.588941 stars\n"
     ]
    }
   ],
   "source": [
    "features_100pos=[[1,0]]\n",
    "features_100neg=[[0,1]]\n",
    "expected_rating_pos = lreg.predict(features_100pos)[0] # I think 0 is for linear as in kernel = {‘linear’, ‘rbf’, ‘poly’, ‘sigmoid’, ‘precomputed’}\n",
    "expected_rating_neg = lreg.predict(features_100neg)[0]\n",
    "print(\"The expected rating for 100 pos review is %f stars\" % expected_rating_pos)\n",
    "print(\"The expected rating  for 100 neg review is %f stars\" % expected_rating_neg)\n",
    "# This model needs a threshold to limit the starts between 0 and 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Repeat this same process for \"Apps for Android\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Apps_for_Android has already been downloaded to ./data/\n"
     ]
    }
   ],
   "source": [
    "###### Getting data####\n",
    "android_dataset = \"Apps_for_Android\"\n",
    "download_data(andorid_dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 752937 data for dataset Apps_for_Android\n",
      "Now we have 451470 training examples, 150182 validation examples, and 151285 test examples\n",
      "{'reviewerID': 'AWUDE6LOH5Y2Q', 'asin': 'B004DLPXAO', 'reviewerName': 'Amazon Customer', 'helpful': [0, 0], 'reviewText': 'Love it!', 'overall': 5.0, 'summary': 'Take you Kindle Library along whenever you have your phone!', 'unixReviewTime': 1404691200, 'reviewTime': '07 7, 2014', 'hash': -5981978766457409355}\n",
      "\n",
      "{'reviewerID': 'A1HZYCWWJ53TS5', 'asin': 'B004HE5TAG', 'helpful': [0, 0], 'reviewText': 'boring', 'overall': 2.0, 'summary': 'Two Stars', 'unixReviewTime': 1405382400, 'reviewTime': '07 15, 2014', 'hash': -7538929081684597848}\n"
     ]
    }
   ],
   "source": [
    "################Processing data############\n",
    "# Load data from directory\n",
    "apps= load_data(android_dataset,datadir)\n",
    "#Partition data for training validation and tests\n",
    "apps_train,apps_valid,apps_test = partition_train_validation_test(apps)\n",
    "#We get the portions of positive and negative terms, omiting stopwords and puntuation marks (tokenizing words and sentences as well))\n",
    "X_apps_train = dataset_to_matrix(apps_train)\n",
    "app_most_pos, app_most_neg = numpy.argmax(X_apps_train, axis=0)\n",
    "print(apps_train[app_most_pos])\n",
    "print()\n",
    "print(apps_train[app_most_neg])\n",
    "Y_apps_train = dataset_to_targets(apps_train) # extract the overall item from each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating for a review with 20 porcet positive comments is 4.655898 stars\n",
      "The expected rating for a review with 20 porcet negative comments is 2.885805 stars\n"
     ]
    }
   ],
   "source": [
    "####Linear regression\n",
    "lreg_app = LinearRegression().fit(X_apps_train, Y_apps_train)\n",
    "app_pos_features = [[0.2, 0]]\n",
    "app_neg_features = [[0,0.2]]\n",
    "expected_rating_pos = lreg.predict(app_pos_features)[0]\n",
    "expected_rating_neg= lreg.predict(app_neg_features)[0]\n",
    "print(\"The expected rating for a review with 20 porcet positive comments is %f stars\" % expected_rating_pos)\n",
    "print(\"The expected rating for a review with 20 porcet negative comments is %f stars\" % expected_rating_neg)\n",
    "#With this data we get sort of a similiar approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training data is 0.941797 stars\n"
     ]
    }
   ],
   "source": [
    "pred_train_apps = predict_lreg(X_apps_train)\n",
    "mae_train_apps = mean_absolute_error(pred_train_apps, Y_apps_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" % mae_train_apps)\n",
    "#We are getting even a higher error with a much more bigger dataset, funny, because it is bigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data contains 21.256400 % dissatisfied customers\n",
      "[False False False False False False False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "def discretize_targets(Y):\n",
    "    return Y<= 3.0 # So this is a boolean, we are returning if the conditions is true\n",
    "D_train = discretize_targets(Y_train) # We must remember that Y_train is a 1 dimension array with the scores\n",
    "print(\"The training data contains %f %% dissatisfied customers\" % (100.*D_train.mean()))\n",
    "print(D_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example number 24850\n",
      "True rating = 2.000000 stars\n",
      "Expected to be dissatisfied: True\n",
      "Expected probability of being dissatisfied : 0.999846\n",
      "Features = 0.000000 / 1.000000\n",
      "Review text = too noisy\n",
      "\n",
      "Training example number 10561\n",
      "True rating = 5.000000 stars\n",
      "Expected to be dissatisfied: False\n",
      "Expected probability of being dissatisfied : 0.000028\n",
      "Features = 1.000000 / 0.000000\n",
      "Review text = work perfect\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train, D_train) # We use just the training data\n",
    "# The predict_proba() method produces a matrix with two columns\n",
    "# the first column contains the probability for the label being \"false\" (satisfied customer)\n",
    "# the second column contains the probability for the label being \"true\" (dissatisfied customer)\n",
    "# the sum of both columns is 1\n",
    "# we select the second column with [:,1]\n",
    "# [:,0] would select the first column\n",
    "# [1,:] would select the second row\n",
    "prob2_train = logreg.predict_proba(X_train)[:,1]\n",
    "pred2_train = prob2_train > 0.5\n",
    "max_prob2 = numpy.argmax(prob2_train)\n",
    "min_prob2 = numpy.argmin(prob2_train)\n",
    "def analyze_training_example_2(i):\n",
    "    print(\"Training example number\", i)\n",
    "    print(\"True rating = %f stars\" % Y_train[i])\n",
    "    print(\"Expected to be dissatisfied:\", pred2_train[i])\n",
    "    print(\"Expected probability of being dissatisfied : %f\" % prob2_train[i])\n",
    "    print(\"Features = %f / %f\" % (X_train[i,0], X_train[i,1]))\n",
    "    print(\"Review text = %s\" % baby_train[i]['reviewText'])\n",
    "    \n",
    "analyze_training_example_2(max_prob2)\n",
    "print()\n",
    "analyze_training_example_2(min_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the default threshold (0.5) we get precision = 0.323503 and recall = 0.735832\n"
     ]
    }
   ],
   "source": [
    "precision2 = precision_score(D_train, pred2_train)\n",
    "recall2 = recall_score(D_train, pred2_train)\n",
    "print(\"For the default threshold (0.5) we get precision = %f \"\n",
    "      \"and recall = %f\" % (precision2, recall2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the precision is 0.476183 and the recall is 0.155316\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB().fit(X_train, D_train)\n",
    "prob3_train = nb.predict_proba(X_train)[:,1]\n",
    "pred3_train = prob3_train>0.5\n",
    "precision3 = precision_score(D_train, pred3_train)\n",
    "recall3 = recall_score(D_train, pred3_train)\n",
    "print(\"Now the precision is %f and the recall is %f\" % (precision3, recall3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Change the treshold from 0.5 to 0.2, and rerun the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the default threshold (0.2) we get precision = 0.323503 and recall = 0.735832\n"
     ]
    }
   ],
   "source": [
    "new_pred2_train = prob2_train > 0.2\n",
    "new_precision = precision_score(D_train, new_pred2_train)\n",
    "new_recall =  recall_score(D_train, new_pred2_train)\n",
    "print(\"For the default threshold (0.2) we get precision = %f \"\n",
    "      \"and recall = %f\" % (new_precision, new_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Give a commentary in plain English about how that changed precision and recall. What does that mean? What is now included that wasn't before? What part of it is good? What is bad from our Task perspective. Remember: our task was to identify Dissatisfied reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features\n",
    "Explain which features you chose, implement them, and write a commentary on your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel welcome to use NLTK's built-in sentiment analyzer or any other research that you can find and understand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAy4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
