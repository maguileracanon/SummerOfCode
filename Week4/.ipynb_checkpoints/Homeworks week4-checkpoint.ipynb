{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base code for basic data we used during the whole week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements - To keed this in order\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from nltk.corpus import opinion_lexicon\n",
    "import urllib.request, os, gzip\n",
    "import  json\n",
    "import random\n",
    "import numpy # a powerfull module\n",
    "import  tensorflow  as tf # Googles ML module\n",
    "from nltk.corpus import stopwords # We use it to remove the stopwords of the comments since they dont provide relevant info\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize , TweetTokenizer # Divide text in sentences and then in words\n",
    "from sklearn.linear_model import LinearRegression # sklearn is a machine learning toolkit (needs numpy, scipy and matplotlib)\n",
    "from sklearn.linear_model import LogisticRegression # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# If I am not mistaken, logistic regresion is for booleans clasiffiers\n",
    "from  sklearn.metrics import precision_score, recall_score # I think these are metrics to evaluate models form the slklearn library\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB # To apply statistical models, not regressions(?)1\n",
    "from  nltk.sentiment  import SentimentAnalyzer\n",
    "from nltk.sentiment.util import mark_negation, HAPPY, SAD #Utilities of negation and happy or sad emojis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Baby has already been downloaded to ./data/\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "datadir = './data/'\n",
    "\n",
    "def download_data(dataset_name, datadir):\n",
    "    filename = 'reviews_%s_5.json' % dataset_name\n",
    "    filepath = os.path.join(datadir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(\"Dataset %s has already been downloaded to %s\" % (dataset_name, datadir))\n",
    "    else:\n",
    "        url = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/%s.gz' % filename\n",
    "        urllib.request.urlretrieve(url, filepath + \".gz\")\n",
    "        with gzip.open(filepath + \".gz\", 'rb') as fin:\n",
    "            with open(filepath, 'wb') as fout:\n",
    "                fout.write(fin.read())\n",
    "        print(\"Downloaded dataset %s and saved it to %s\" % (dataset_name, datadir))\n",
    "\n",
    "dataset = \"Baby\"\n",
    "download_data(dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 160792 data for dataset Baby\n"
     ]
    }
   ],
   "source": [
    "def  load_data (dataset_name, datadir):\n",
    "    filepath = os.path.join(datadir, 'reviews_%s_5.json' % dataset_name)\n",
    "    if not os.path.exists(filepath):\n",
    "        download_data(dataset_name, datadir)\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:                            # read file line by line\n",
    "            item_hash = hash(line)                # we will use this later for partitioning our data \n",
    "            item = json.loads(line)               # convert JSON string to Python dict\n",
    "            item['hash'] = item_hash              # add hash for identification purposes\n",
    "            data.append(item)\n",
    "    print(\"Loaded %d data for dataset %s\" % (len(data), dataset_name))\n",
    "    return data\n",
    "\n",
    "# load the data...\n",
    "baby = load_data(dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 96253 training examples, 32080 validation examples, and 32459 test examples\n"
     ]
    }
   ],
   "source": [
    "def partition_train_validation_test(data):\n",
    "    # 60% : modulus is 0, 1, 2, 3, 4, or 5\n",
    "    data_train = [item for item in data if item['hash']%10<=5]  \n",
    "    # 20% : modulus is 6 or 7\n",
    "    data_valid = [item for item in data if item['hash']%10 in [6,7]] \n",
    "    # 20% : modulus is 8 or 9\n",
    "    data_test  = [item for item in data if item['hash']%10 in [8,9]] \n",
    "    print(\"Now we have\", len(data_train), \"training examples,\", len(data_valid),\n",
    "      \"validation examples, and\", len(data_test), \"test examples\")\n",
    "    return data_train, data_valid, data_test\n",
    "    \n",
    "baby_train, baby_valid, baby_test = partition_train_validation_test(baby)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8571428571428571, 0.0)\n",
      "(0.0, 0.8571428571428571)\n"
     ]
    }
   ],
   "source": [
    "eng_stopwords = set(stopwords.words('english'))\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "def my_tokenize(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        #Adds to the array and array with the words in lowercase, we add them if they are not stopwords and there is at least one letter in it\n",
    "        tokens.extend(x for x in word_tokenize(sentence.lower()) #continues down...\n",
    "                      if x not in eng_stopwords and any(i.isalpha() for i in x))# This extends the list by adding elements, it is different from append... see https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python \n",
    "    return tokens\n",
    "\n",
    "def pos_neg_fraction(text): # We recieve the raw text\n",
    "    tokens = my_tokenize(text) # We tokenize the text first\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in positive_words:\n",
    "            count_pos += 1\n",
    "        if t in negative_words:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens) # this is because we need to be sure there is no 0 len sentence\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:\n",
    "        return 0., 0.\n",
    "    \n",
    "pos_example = 'This is a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example = 'This is a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction(pos_example))\n",
    "print(pos_neg_fraction(neg_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found a fraction of 100.000000 % positive words for example 5837\n",
      "{'reviewerID': 'AKU0ZZ3IEZW42', 'asin': 'B0001BUKA8', 'helpful': [0, 0], 'reviewText': 'useful peace', 'overall': 5.0, 'summary': 'Five Stars', 'unixReviewTime': 1405382400, 'reviewTime': '07 15, 2014', 'hash': 7107190353628296494}\n",
      "We found a fraction of 100.000000 % negative words for example 15668\n",
      "{'reviewerID': 'A2416HDN71TOGG', 'asin': 'B000HZEQSU', 'reviewerName': 'Elizabeth Evans', 'helpful': [0, 0], 'reviewText': 'uncomfortable', 'overall': 1.0, 'summary': 'One Star', 'unixReviewTime': 1404691200, 'reviewTime': '07 7, 2014', 'hash': -3205723466346788000}\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_matrix(data):\n",
    "    # data is a lot of text in {} that has reviwer name..comment...date...etc.. but all identified with text labels\n",
    "    #in that sence data is an unidiminsional array\n",
    "    # the item \"atribute\", we added it to the data to identify the sections of it\n",
    "    return numpy.array([list(pos_neg_fraction(item['reviewText'])) for item in data])\n",
    "# X_train with two columns and as many rows as there are examples in the data set. \n",
    "#The first column contains the fraction of positive words, \n",
    "#while the second column contains the fraction of negative words for each example.\n",
    "X_train = dataset_to_matrix(baby_train)\n",
    "X_valid = dataset_to_matrix(baby_valid)\n",
    "X_test = dataset_to_matrix(baby_test)\n",
    "most_pos, most_neg = numpy.argmax(X_train, axis=0) # find maximum ROW (axis 0).. through aaaaallll the data (OMG!)\n",
    "# print the example with the highest fraction of positive words:\n",
    "print(\"We found a fraction of %f %% positive words for example %d\" % \n",
    "      (100.*X_train[most_pos, 0], most_pos))\n",
    "print(baby_train[most_pos])\n",
    "print(\"We found a fraction of %f %% negative words for example %d\" %\n",
    "      (100.*X_train[most_neg, 1], most_neg))\n",
    "print(baby_train[most_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our feature matrix is two-dimensional and has shape (96253, 2)\n",
      "Our target vector is one-dimensional and has shape (96253,)\n"
     ]
    }
   ],
   "source": [
    "def  dataset_to_targets (data):\n",
    "    return numpy.array([item['overall'] for item in data])\n",
    "\n",
    "Y_train = dataset_to_targets(baby_train)\n",
    "Y_valid = dataset_to_targets(baby_valid)\n",
    "Y_test = dataset_to_targets(baby_test)\n",
    "print(\"Our feature matrix is two-dimensional and has shape\", X_train.shape) # contains pos,neg fraction\n",
    "print(\"Our target vector is one-dimensional and has shape\", Y_train.shape) # containd sscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for the fpos variable is 3.142702448525493\n",
      "The coefficient for the fneg variable is -5.747085319024815\n",
      "The intercept is 4.025500815774261\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression().fit(X_train,Y_train)\n",
    "print(\"The coefficient for the fpos variable is\", lreg.coef_[0])\n",
    "print(\"The coefficient for the fneg variable is\", lreg.coef_[1])\n",
    "print(\"The intercept is\", lreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is 4.654041 stars\n",
      "This is the same as 4.654041 stars\n",
      "The expected rating is 2.876084 stars\n",
      "This is the same as 2.876084 stars\n"
     ]
    }
   ],
   "source": [
    "#If the review contains 20% positive words (fpos==0.2) \n",
    "#but still no negative words (fneg==0), we would expect the following rating:\n",
    "features = [[0.2, 0]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0.2*lreg.coef_[0] + 0*lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)\n",
    "#However, if the review contains no positive words (fpos==0) but 20% negative words (fneg==0.2),\n",
    "#we expect the following rating:\n",
    "features = [[0, 0.2]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0 * lreg.coef_[0] + 0.2 * lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lreg(features):\n",
    "    expected_rating = lreg.predict(features)\n",
    "    expected_rating[expected_rating > 5.0] = 5.0\n",
    "    expected_rating[expected_rating < 1.0] = 1.0\n",
    "    return expected_rating\n",
    "\n",
    "pred_train = predict_lreg(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training data is 0.830250 stars\n"
     ]
    }
   ],
   "source": [
    "mae_train = mean_absolute_error(pred_train, Y_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" % mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - calculate the prediction for 100% pos, and 100% neg review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating for 100 pos review is 7.168203 stars\n",
      "The expected rating  for 100 neg review is -1.721585 stars\n"
     ]
    }
   ],
   "source": [
    "features_100pos=[[1,0]]\n",
    "features_100neg=[[0,1]]\n",
    "expected_rating_pos = lreg.predict(features_100pos)[0] # I think 0 is for linear as in kernel = {‘linear’, ‘rbf’, ‘poly’, ‘sigmoid’, ‘precomputed’}\n",
    "expected_rating_neg = lreg.predict(features_100neg)[0]\n",
    "print(\"The expected rating for 100 pos review is %f stars\" % expected_rating_pos)\n",
    "print(\"The expected rating  for 100 neg review is %f stars\" % expected_rating_neg)\n",
    "# This model needs a threshold to limit the starts between 0 and 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Repeat this same process for \"Apps for Android\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Apps_for_Android has already been downloaded to ./data/\n"
     ]
    }
   ],
   "source": [
    "###### Getting data####\n",
    "android_dataset = \"Apps_for_Android\"\n",
    "download_data(android_dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 752937 data for dataset Apps_for_Android\n",
      "Now we have 451391 training examples, 151463 validation examples, and 150083 test examples\n",
      "{'reviewerID': 'AWUDE6LOH5Y2Q', 'asin': 'B004DLPXAO', 'reviewerName': 'Amazon Customer', 'helpful': [0, 0], 'reviewText': 'Love it!', 'overall': 5.0, 'summary': 'Take you Kindle Library along whenever you have your phone!', 'unixReviewTime': 1404691200, 'reviewTime': '07 7, 2014', 'hash': -6442649921102621376}\n",
      "\n",
      "{'reviewerID': 'A33B1XSEPC34ND', 'asin': 'B004JKOYGS', 'reviewerName': 'P. Church', 'helpful': [0, 0], 'reviewText': 'Unknown', 'overall': 3.0, 'summary': 'Three Stars', 'unixReviewTime': 1403740800, 'reviewTime': '06 26, 2014', 'hash': -8221447696170989809}\n"
     ]
    }
   ],
   "source": [
    "################Processing data############\n",
    "# Load data from directory\n",
    "apps= load_data(android_dataset,datadir)\n",
    "#Partition data for training validation and tests\n",
    "apps_train,apps_valid,apps_test = partition_train_validation_test(apps)\n",
    "#We get the portions of positive and negative terms, omiting stopwords and puntuation marks (tokenizing words and sentences as well))\n",
    "X_apps_train = dataset_to_matrix(apps_train)\n",
    "app_most_pos, app_most_neg = numpy.argmax(X_apps_train, axis=0)\n",
    "print(apps_train[app_most_pos])\n",
    "print()\n",
    "print(apps_train[app_most_neg])\n",
    "Y_apps_train = dataset_to_targets(apps_train) # extract the overall item from each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating for a review with 20 porcet positive comments is 4.654041 stars\n",
      "The expected rating for a review with 20 porcet negative comments is 2.876084 stars\n"
     ]
    }
   ],
   "source": [
    "####Linear regression\n",
    "lreg_app = LinearRegression().fit(X_apps_train, Y_apps_train)\n",
    "app_pos_features = [[0.2, 0]]\n",
    "app_neg_features = [[0,0.2]]\n",
    "expected_rating_pos = lreg.predict(app_pos_features)[0]\n",
    "expected_rating_neg= lreg.predict(app_neg_features)[0]\n",
    "print(\"The expected rating for a review with 20 porcet positive comments is %f stars\" % expected_rating_pos)\n",
    "print(\"The expected rating for a review with 20 porcet negative comments is %f stars\" % expected_rating_neg)\n",
    "#With this data we get sort of a similiar approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training data is 0.942938 stars\n"
     ]
    }
   ],
   "source": [
    "pred_train_apps = predict_lreg(X_apps_train)\n",
    "mae_train_apps = mean_absolute_error(pred_train_apps, Y_apps_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" % mae_train_apps)\n",
    "#We are getting even a higher error with a much more bigger dataset, funny, because it is bigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data contains 21.242974 % dissatisfied customers\n",
      "[False False False  True False False False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "def discretize_targets(Y):\n",
    "    return Y<= 3.0 # So this is a boolean, we are returning if the conditions is true\n",
    "D_train = discretize_targets(Y_train) # We must remember that Y_train is a 1 dimension array with the scores\n",
    "print(\"The training data contains %f %% dissatisfied customers\" % (100.*D_train.mean()))\n",
    "print(D_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example number 15668\n",
      "True rating = 1.000000 stars\n",
      "Expected to be dissatisfied: True\n",
      "Expected probability of being dissatisfied : 0.999872\n",
      "Features = 0.000000 / 1.000000\n",
      "Review text = uncomfortable\n",
      "\n",
      "Training example number 5837\n",
      "True rating = 5.000000 stars\n",
      "Expected to be dissatisfied: False\n",
      "Expected probability of being dissatisfied : 0.000040\n",
      "Features = 1.000000 / 0.000000\n",
      "Review text = useful peace\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train, D_train) # We use just the training data\n",
    "# The predict_proba() method produces a matrix with two columns\n",
    "# the first column contains the probability for the label being \"false\" (satisfied customer)\n",
    "# the second column contains the probability for the label being \"true\" (dissatisfied customer)\n",
    "# the sum of both columns is 1\n",
    "# we select the second column with [:,1]\n",
    "# [:,0] would select the first column\n",
    "# [1,:] would select the second row\n",
    "prob2_train = logreg.predict_proba(X_train)[:,1]\n",
    "pred2_train = prob2_train > 0.5\n",
    "max_prob2 = numpy.argmax(prob2_train)\n",
    "min_prob2 = numpy.argmin(prob2_train)\n",
    "def analyze_training_example_2(i):\n",
    "    print(\"Training example number\", i)\n",
    "    print(\"True rating = %f stars\" % Y_train[i])\n",
    "    print(\"Expected to be dissatisfied:\", pred2_train[i])\n",
    "    print(\"Expected probability of being dissatisfied : %f\" % prob2_train[i])\n",
    "    print(\"Features = %f / %f\" % (X_train[i,0], X_train[i,1]))\n",
    "    print(\"Review text = %s\" % baby_train[i]['reviewText'])\n",
    "    \n",
    "analyze_training_example_2(max_prob2)\n",
    "print()\n",
    "analyze_training_example_2(min_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the default threshold (0.5) we get precision = 0.605487 and recall = 0.093901\n"
     ]
    }
   ],
   "source": [
    "precision2 = precision_score(D_train, pred2_train)\n",
    "recall2 = recall_score(D_train, pred2_train)\n",
    "print(\"For the default threshold (0.5) we get precision = %f \"\n",
    "      \"and recall = %f\" % (precision2, recall2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the precision is 0.484075 and the recall is 0.156845\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB().fit(X_train, D_train)\n",
    "prob3_train = nb.predict_proba(X_train)[:,1]\n",
    "pred3_train = prob3_train>0.5\n",
    "precision3 = precision_score(D_train, pred3_train)\n",
    "recall3 = recall_score(D_train, pred3_train)\n",
    "print(\"Now the precision is %f and the recall is %f\" % (precision3, recall3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Change the treshold from 0.5 to 0.2, and rerun the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the default threshold (0.2) we get precision = 0.321344 and recall = 0.733653\n"
     ]
    }
   ],
   "source": [
    "new_pred2_train = prob2_train > 0.2\n",
    "new_precision = precision_score(D_train, new_pred2_train)\n",
    "new_recall =  recall_score(D_train, new_pred2_train)\n",
    "print(\"For the default threshold (0.2) we get precision = %f \"\n",
    "      \"and recall = %f\" % (new_precision, new_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Give a commentary in plain English about how that changed precision and recall. What does that mean? What is now included that wasn't before? What part of it is good? What is bad from our Task perspective. Remember: our task was to identify Dissatisfied reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is droping because we are taking more cases as valid (dissatisfied costumers) as our threshold is lower, however there are more chances that a higher proportion of cases labaled as \"dissatisfied\" where actually sattisfied. From our problem perspective I think it is better to encrease the recall as I guess we are more interested in identifiying dissatisfied costumers to address the product's problems ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Mara\\AppData\\Local\\Temp\\tmp29duto9d\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Mara\\\\AppData\\\\Local\\\\Temp\\\\tmp29duto9d', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000028BD3D0FC18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Mara\\AppData\\Local\\Temp\\tmp29duto9d\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2505.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 602.424\n",
      "INFO:tensorflow:loss = 254.43304, step = 101 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.542\n",
      "INFO:tensorflow:loss = 206.44287, step = 201 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 943.384\n",
      "INFO:tensorflow:loss = 131.5999, step = 301 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.916\n",
      "INFO:tensorflow:loss = 150.68257, step = 401 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.137\n",
      "INFO:tensorflow:loss = 209.64456, step = 501 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.292\n",
      "INFO:tensorflow:loss = 135.35257, step = 601 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 751.872\n",
      "INFO:tensorflow:loss = 157.11493, step = 701 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.456\n",
      "INFO:tensorflow:loss = 134.14244, step = 801 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.999\n",
      "INFO:tensorflow:loss = 132.2709, step = 901 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.1\n",
      "INFO:tensorflow:loss = 171.04938, step = 1001 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.441\n",
      "INFO:tensorflow:loss = 170.93369, step = 1101 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1020.38\n",
      "INFO:tensorflow:loss = 114.1548, step = 1201 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.549\n",
      "INFO:tensorflow:loss = 216.51703, step = 1301 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.092\n",
      "INFO:tensorflow:loss = 151.84384, step = 1401 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.057\n",
      "INFO:tensorflow:loss = 195.24841, step = 1501 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.179\n",
      "INFO:tensorflow:loss = 162.88196, step = 1601 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 926.018\n",
      "INFO:tensorflow:loss = 127.44698, step = 1701 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.36\n",
      "INFO:tensorflow:loss = 205.52669, step = 1801 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1020.43\n",
      "INFO:tensorflow:loss = 133.79749, step = 1901 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.538\n",
      "INFO:tensorflow:loss = 174.4011, step = 2001 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.27\n",
      "INFO:tensorflow:loss = 132.58618, step = 2101 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.85\n",
      "INFO:tensorflow:loss = 180.6218, step = 2201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1063.86\n",
      "INFO:tensorflow:loss = 173.31439, step = 2301 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1086.96\n",
      "INFO:tensorflow:loss = 137.18663, step = 2401 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.06\n",
      "INFO:tensorflow:loss = 133.55534, step = 2501 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.597\n",
      "INFO:tensorflow:loss = 259.36688, step = 2601 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.13\n",
      "INFO:tensorflow:loss = 109.60887, step = 2701 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1041.79\n",
      "INFO:tensorflow:loss = 189.45512, step = 2801 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1030.88\n",
      "INFO:tensorflow:loss = 145.86914, step = 2901 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.059\n",
      "INFO:tensorflow:loss = 150.57262, step = 3001 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1000.11\n",
      "INFO:tensorflow:loss = 135.47441, step = 3101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.331\n",
      "INFO:tensorflow:loss = 136.19485, step = 3201 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.435\n",
      "INFO:tensorflow:loss = 221.50438, step = 3301 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.421\n",
      "INFO:tensorflow:loss = 119.56642, step = 3401 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.877\n",
      "INFO:tensorflow:loss = 175.39304, step = 3501 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1041.48\n",
      "INFO:tensorflow:loss = 144.65712, step = 3601 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.524\n",
      "INFO:tensorflow:loss = 135.2627, step = 3701 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1063.86\n",
      "INFO:tensorflow:loss = 136.94452, step = 3801 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1030.9\n",
      "INFO:tensorflow:loss = 143.00421, step = 3901 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.901\n",
      "INFO:tensorflow:loss = 166.699, step = 4001 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1063.79\n",
      "INFO:tensorflow:loss = 164.85461, step = 4101 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1041.68\n",
      "INFO:tensorflow:loss = 161.50427, step = 4201 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1000.02\n",
      "INFO:tensorflow:loss = 164.55785, step = 4301 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.994\n",
      "INFO:tensorflow:loss = 176.35437, step = 4401 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1086.93\n",
      "INFO:tensorflow:loss = 171.23824, step = 4501 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.3\n",
      "INFO:tensorflow:loss = 171.98615, step = 4601 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.794\n",
      "INFO:tensorflow:loss = 177.32414, step = 4701 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.24\n",
      "INFO:tensorflow:loss = 129.04024, step = 4801 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.41\n",
      "INFO:tensorflow:loss = 110.27975, step = 4901 (0.093 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\Mara\\AppData\\Local\\Temp\\tmp29duto9d\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 181.36238.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x28c13d44748>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols = [tf.feature_column.numeric_column(key=\"fpos\"),\n",
    "             tf.feature_column.numeric_column(key=\"fneg\")]\n",
    "model = tf.estimator.LinearRegressor(feature_columns=feat_cols)\n",
    "get_training_data = tf.estimator.inputs.numpy_input_fn(\n",
    "                     x={\"fpos\" : X_train[:,0], \"fneg\" : X_train[:,1]},\n",
    "                     y=Y_train, num_epochs=None, shuffle=True)\n",
    "\n",
    "model.train(input_fn=get_training_data, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Mara\\AppData\\Local\\Temp\\tmp29duto9d\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "The mean absolute error on the training data is 0.841525 stars\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_training_data = tf.estimator.inputs.numpy_input_fn(\n",
    "                     x={\"fpos\":X_train[:,0], \"fneg\": X_train[:,1]},\n",
    "                     num_epochs=1, shuffle=False)\n",
    "pred_train_tf = numpy.array([item['predictions'][0] for item in \n",
    "                         model.predict(input_fn=eval_training_data)])\n",
    "mae_train_tf = mean_absolute_error(pred_train_tf, Y_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" \n",
    "      % mae_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence = This product wasn't bad.\n",
      "['this', 'product', 'was', \"n't\", 'bad_NEG', '.']\n",
      "Sentence = This is not a bad product.\n",
      "['this', 'is', 'not', 'a_NEG', 'bad_NEG', 'product_NEG', '.']\n",
      "Sentence = This product was bad.\n",
      "['this', 'product', 'was', 'bad', '.']\n",
      "Sentence = This is a bad product.\n",
      "['this', 'is', 'a', 'bad', 'product', '.']\n",
      "This is a wonderful toy that is fun, educational, and affordable! The cars are different colors, and each has a different number, 1 - 4, to help a child learn counting and colors. They also stack on top of each other and nest inside of each other.(The nesting feature is great for storage too). Each car has a neat fun feature for little ones to explore (e.g., the small car is also a rattle, the large fire truck's ladder moves, etc.) The cars are also very sturdy (as has been proven by my son repeatedly banging them together,) and they are easy for little hands to grab onto. At 6 months of age, my son really enjoys looking at the toys, passing them from one hand to the other, banging them together, and, of course, putting them in his mouth. I imagine this toy will remain one of my son's favorites as he learns to stack them and roll them on the floor. I would highly recommend this item.\n",
      "['wonderful', 'toy', 'fun', 'educational', 'affordable', 'cars', 'different', 'colors', 'different', 'number', 'help', 'child', 'learn', 'counting', 'colors', 'also', 'stack', 'top', 'nest', 'inside', 'nesting', 'feature', 'great', 'storage', 'car', 'neat', 'fun', 'feature', 'little', 'ones', 'explore', 'e.g.', 'small', 'car', 'also', 'rattle', 'large', 'fire', 'truck', \"'s\", 'ladder', 'moves', 'etc', 'cars', 'also', 'sturdy', 'proven', 'son', 'repeatedly', 'banging', 'together', 'easy', 'little', 'hands', 'grab', 'onto', 'months', 'age', 'son', 'really', 'enjoys', 'looking', 'toys', 'passing', 'one', 'hand', 'banging', 'together', 'course', 'putting', 'mouth', 'imagine', 'toy', 'remain', 'one', 'son', \"'s\", 'favorites', 'learns', 'stack', 'roll', 'floor', 'would', 'highly', 'recommend', 'item']\n"
     ]
    }
   ],
   "source": [
    "examples_negation = [\"This product wasn't bad.\",\n",
    "                     \"This is not a bad product.\",\n",
    "                     \"This product was bad.\",\n",
    "                     \"This is a bad product.\"]\n",
    "\n",
    "for sentence in examples_negation:\n",
    "    tokens_with_negation = mark_negation(word_tokenize(sentence.lower())) # Append _NEG suffix to words that appear in the scope between a negation and a punctuation mark.\n",
    "    print(\"Sentence =\", sentence)\n",
    "    print(tokens_with_negation)\n",
    "\n",
    "negated_stopwords = set(x+\"_NEG\" for x in eng_stopwords)\n",
    "all_stopwords = eng_stopwords.union(negated_stopwords)   # set union stopwords and negate stopwords\n",
    "    \n",
    "def tokenize_with_negation(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        pretokens = word_tokenize(sentence.lower())\n",
    "        pretokens = [x for x in pretokens if any(i.isalpha() for i in x)] #Everything the same unitl here\n",
    "        #Append _NEG suffix to words that appear in the scope between a negation \n",
    "        #and a punctuation mark\n",
    "        pretokens = mark_negation(pretokens) #Here\n",
    "        # ok, but tokens started empy so we are bsically storing the array\n",
    "        tokens.extend(x for x in pretokens if x not in all_stopwords) # puts a list at the beegining of the frist list\n",
    "    return tokens\n",
    "\n",
    "print(baby_train[31]['reviewText'])\n",
    "print(tokenize_with_negation(baby_train[31]['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8571428571428571, 0.0)\n",
      "(0.0, 0.8571428571428571)\n",
      "(0.0, 0.8571428571428571)\n",
      "(0.8571428571428571, 0.0)\n"
     ]
    }
   ],
   "source": [
    "all_positive_words = positive_words.union({x+\"_NEG\" for x in negative_words})\n",
    "all_negative_words = negative_words.union({x+\"_NEG\" for x in positive_words})\n",
    "def pos_neg_fraction_with_negation(text):\n",
    "    tokens = tokenize_with_negation(text) #Tokenize and adds negation when necessary\n",
    "    # count how many positive and negative words occur in the text\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in all_positive_words:\n",
    "            count_pos += 1\n",
    "        if t in all_negative_words:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens)\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:  # avoid division by zero\n",
    "        return 0., 0.\n",
    "    \n",
    "pos_example = 'This is a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example = 'This is a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction_with_negation(pos_example))\n",
    "print(pos_neg_fraction_with_negation(neg_example))\n",
    "pos_example_neg = 'This is not a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example_neg = 'This is not a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction_with_negation(pos_example_neg))\n",
    "print(pos_neg_fraction_with_negation(neg_example_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_matrix_with_neg(data):\n",
    "    return numpy.array([list(pos_neg_fraction_with_negation(item['reviewText'])) for item in data])\n",
    "\n",
    "X_train_neg = dataset_to_matrix_with_neg(baby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.813565 stars\n"
     ]
    }
   ],
   "source": [
    "lreg_neg = LinearRegression().fit(X_train_neg, Y_train)\n",
    "pred_train_neg = lreg_neg.predict(X_train_neg)\n",
    "mae_train_with_neg = mean_absolute_error(pred_train_neg, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f stars\" % mae_train_with_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A nonlinear regressor achieves a MAE of 0.713438 stars\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_neg = RandomForestRegressor().fit(X_train_neg,Y_train)\n",
    "pred_train_rf_neg = rf_neg.predict(X_train_neg)\n",
    "mae_train_rf_neg = mean_absolute_error(pred_train_rf_neg, Y_train)\n",
    "print(\"A nonlinear regressor achieves a MAE of %f stars\" % mae_train_rf_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add features , Explain which features you chose, implement them, and write a commentary on your results... Feel welcome to use NLTK's built-in sentiment analyzer or any other research that you can find and understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add emojis (personal choice, I communicate with emojis the whole time), also if a word is in uupercases then it will count as 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_negation_Emojis(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    tknzr = TweetTokenizer()\n",
    "    for sentence in sent_tokenize(text):\n",
    "        #pretokens = word_tokenize(sentence.lower())\n",
    "        emopretokens = tknzr.tokenize(sentence) #use tweet tokenizer to include emojis\n",
    "        emojis  = [x for x in emopretokens if x in SAD or x in HAPPY]\n",
    "        # if a word is in uppercase then count ir twice \n",
    "        pretokens_emphasis = [x for x in emopretokens if x.isupper() and x.isalpha()]\n",
    "        pretokens = word_tokenize(sentence.lower())\n",
    "        pretokens = [x for x in pretokens if any(i.isalpha() for i in x)] #Everything the same unitl here\n",
    "        #Append _NEG suffix to words that appear in the scope between a negation \n",
    "        #and a punctuation mark\n",
    "        pretokens.extend(pretokens_emphasis)\n",
    "        pretokens = mark_negation(pretokens) #Here\n",
    "        pretokens.extend(emojis)\n",
    "        # ok, but tokens started empy so we are bsically storing the array\n",
    "        tokens.extend(x for x in pretokens if x not in all_stopwords) # puts a list at the beegining of the frist list\n",
    "    return tokens\n",
    "\n",
    "all_positive_words_emoji = all_positive_words.union(HAPPY)\n",
    "all_negative_words_emoji = all_negative_words.union(SAD)\n",
    "\n",
    "def pos_neg_fraction_with_negation_emoji(text):\n",
    "    tokens = tokenize_with_negation_Emojis(text) #Tokenize and adds negation when necessary\n",
    "    # count how many positive and negative words occur in the text\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in all_positive_words_emoji:\n",
    "            count_pos += 1\n",
    "        if t in all_negative_words_emoji:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens)\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:  # avoid division by zero\n",
    "        return 0., 0.\n",
    "def dataset_to_matrix_with_neg_emoji(data):\n",
    "    return numpy.array([list(pos_neg_fraction_with_negation_emoji(item['reviewText'])) for item in data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.0)\n",
      "(0.0, 1.0)\n",
      "I bought these bottles after reading reviews on them and have been pretty happy with them. They have never leaked with me BUT I have never screwed the lid on too tightly. You HAVE to remember that. When you overtighten the lid, the nipple gets distorted and the seal is broken. My husband and others in the family have had this problem. It is probably always helpful to test for leaks (when you test the temp of the milk) BEFORE you give it to the baby, just to make sure.I like the plastic they use. It has always felt extremely sturdy. They are easily to hold (thanks to the curve) and I really like the wide mouth of the bottles which make them easy to clean....and you are pretty sure they are clean!!I bought the newborn starter set and the infant set and together they are all I require for bottles and a breastmilk storage set!!All in all I think they were a great buy and worth it. I would use them all over again and would use avent with my next baby too.\n",
      "(0.13978494623655913, 0.043010752688172046)\n"
     ]
    }
   ],
   "source": [
    "my_example =\" :D :) ;) \"\n",
    "print(pos_neg_fraction_with_negation_emoji(my_example))\n",
    "my_example = \":( :/)\"\n",
    "print(pos_neg_fraction_with_negation_emoji(my_example))\n",
    "print(baby_train[700]['reviewText'])\n",
    "print(pos_neg_fraction_with_negation_emoji(baby_train[700]['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_neg_emoji = dataset_to_matrix_with_neg_emoji(baby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.813530 stars\n"
     ]
    }
   ],
   "source": [
    "lreg_neg_emoji = LinearRegression().fit(X_train_neg_emoji, Y_train)\n",
    "pred_train_neg_emoji = lreg_neg_emoji.predict(X_train_neg_emoji)\n",
    "mae_train_with_neg_emoji = mean_absolute_error(pred_train_neg_emoji, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f stars\" % mae_train_with_neg_emoji)\n",
    "# I managed to improve the model a littttllleee bit :P 0.813530 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'HUGE', '!', '!', ':D']\n",
      "['this', 'is', 'HUGE', '!', '!', ':', 'D']\n"
     ]
    }
   ],
   "source": [
    "#Diferences between the tokenizers\n",
    "print(TweetTokenizer().tokenize(\"this is HUGE!! :D \"))\n",
    "print(word_tokenize(\"this is HUGE!! :D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is good for piece of mind, but mine kept slipping off.\n",
      "{'neg': 0.0, 'neu': 0.849, 'pos': 0.151, 'compound': 0.2382}\n",
      "It doesn't work well with cloth diapers.\n",
      "{'neg': 0.232, 'neu': 0.768, 'pos': 0.0, 'compound': -0.2057}\n",
      "Oh well.\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n"
     ]
    }
   ],
   "source": [
    "sia= SentimentIntensityAnalyzer()\n",
    "text = baby_train[50000]['reviewText']\n",
    "for s in sent_tokenize(text):\n",
    "    print(s)\n",
    "    print(sia.polarity_scores(s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sia_features(dataset):\n",
    "    '''\n",
    "    For each review text in the dataset, extract: \n",
    "    (1) mean positive sentiment over all sentences\n",
    "    (2) mean neutral sentiment over all sentences\n",
    "    (3) mean negative sentiment over all  sentences\n",
    "    (4) maximum postive sentiment over all sentences\n",
    "    (5) maximum neutral sentiment over all sentences\n",
    "    (6) maximum negative sentiment over al sentences \n",
    "'''\n",
    "    feat_matrix = numpy.empty((len(dataset),6))\n",
    "    for i in range(len(dataset)):\n",
    "        sentences = sent_tokenize(dataset[i]['reviewText'])\n",
    "        nsent = len(sentences)\n",
    "        if nsent:\n",
    "            sentences_polarities = numpy.empty((nsent,3))\n",
    "            for j in range(nsent):\n",
    "                polarity = sia.polarity_scores(sentences[j])\n",
    "                sentences_polarities[j,0] = polarity['pos']\n",
    "                sentences_polarities[j,1] = polarity['neu']\n",
    "                sentences_polarities[j,2] = polarity['neg']\n",
    "            feat_matrix[i, 0:3] = numpy.mean(sentences_polarities, axis = 0) #axis 0 is row, axis 1 is columns\n",
    "            feat_matrix[i,3:6] = numpy.max(sentences_polarities, axis = 0)\n",
    "        else:\n",
    "            feat_matrix[i, 0:6] = 0.0\n",
    "            \n",
    "    return feat_matrix\n",
    "            \n",
    "sia_tr = sia_features(baby_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Homework** : add lenght function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_features(dataset):\n",
    "    '''\n",
    "    Add two features:\n",
    "    (1) lenght of review (in thousands of characters) - truncate at 2500\n",
    "    (2) percengate of exclamation marks (in %)    \n",
    "    '''\n",
    "    lenfeat_matrix =  numpy.empty(len(dataset),2)\n",
    "    for i in range(len(dataset)):\n",
    "        review_len = (len(dataset[i]['reviewText']))/1000 \n",
    "        if (review_len >= 2500):\n",
    "            review_len = 2500\n",
    "len_tr = len_features(baby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.757070 starts\n"
     ]
    }
   ],
   "source": [
    "# stack horizontally \n",
    "X_train_augmented = numpy.concatenate(( X_train_neg, sia_tr) ,axis = 1)\n",
    "lreg_augmented = LinearRegression().fit(X_train_augmented,Y_train)\n",
    "pred_train_augmented = lreg_augmented.predict(X_train_augmented)\n",
    "mean_train_augmented = mean_absolute_error(pred_train_augmented, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f starts\" % mean_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the RF, MAE is 0.292269 stars\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rf_augmented = RandomForestRegressor().fit(X_train_augmented, Y_train) #fetting\n",
    "rfpred_train_augmented = rf_augmented.predict(X_train_augmented) # prediction\n",
    "mae_train_rf_augmented = mean_absolute_error(rfpred_train_augmented, Y_train) #check error\n",
    "print(\"For the RF, MAE is %f stars\" % mae_train_rf_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on the validation set, we get 0.760466 error for the linear regresion\n",
      "and 0.756154  for the random forest regresion\n"
     ]
    }
   ],
   "source": [
    "X_valid_neg = dataset_to_matrix(baby_valid)\n",
    "sia_valid = sia_features(baby_valid)\n",
    "#leng_valid\n",
    "X_valid_augmented = numpy.concatenate((X_valid_neg,sia_valid), axis = 1)\n",
    "pred_valid_lraugmented = lreg_augmented.predict(X_valid_augmented)\n",
    "pred_valid_rf_augmented = rf_augmented.predict(X_valid_augmented)\n",
    "\n",
    "mae_valid_augmented = mean_absolute_error(pred_valid_lraugmented, Y_valid)\n",
    "print(\"on the validation set, we get %f error for the linear regresion\" % mae_valid_augmented)\n",
    "mae_valid_rfaugemented = mean_absolute_error(pred_valid_rf_augmented, Y_valid)\n",
    "print(\"and %f  for the random forest regresion\" % mae_valid_rfaugemented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HOMEWORK**  =\"Be lazy. Not just lazy but proactively, agressively lazy.\" Remove duplication.\n",
    "create a single function that takes in data and spits out all success metrics across all of your algos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
