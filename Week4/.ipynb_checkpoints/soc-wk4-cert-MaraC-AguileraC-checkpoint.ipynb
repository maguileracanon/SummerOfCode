{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base code for basic data we used during the whole week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maguileracanon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "#Import statements - To keed this in order\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from nltk.corpus import opinion_lexicon\n",
    "import urllib.request, os, gzip\n",
    "import  json\n",
    "import random\n",
    "import numpy # a powerfull module\n",
    "import  tensorflow  as tf # Googles ML module\n",
    "from nltk.corpus import stopwords # We use it to remove the stopwords of the comments since they dont provide relevant info\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize , TweetTokenizer # Divide text in sentences and then in words\n",
    "from sklearn.linear_model import LinearRegression # sklearn is a machine learning toolkit (needs numpy, scipy and matplotlib)\n",
    "from sklearn.linear_model import LogisticRegression # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# If I am not mistaken, logistic regresion is for booleans clasiffiers\n",
    "from  sklearn.metrics import precision_score, recall_score # I think these are metrics to evaluate models form the slklearn library\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB # To apply statistical models, not regressions(?)1\n",
    "from  nltk.sentiment  import SentimentAnalyzer\n",
    "from nltk.sentiment.util import mark_negation, HAPPY, SAD #Utilities of negation and happy or sad emojis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Baby has already been downloaded to ./data/\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "datadir = './data/'\n",
    "\n",
    "def download_data(dataset_name, datadir):\n",
    "    filename = 'reviews_%s_5.json' % dataset_name\n",
    "    filepath = os.path.join(datadir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(\"Dataset %s has already been downloaded to %s\" % (dataset_name, datadir))\n",
    "    else:\n",
    "        url = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/%s.gz' % filename\n",
    "        urllib.request.urlretrieve(url, filepath + \".gz\")\n",
    "        with gzip.open(filepath + \".gz\", 'rb') as fin:\n",
    "            with open(filepath, 'wb') as fout:\n",
    "                fout.write(fin.read())\n",
    "        print(\"Downloaded dataset %s and saved it to %s\" % (dataset_name, datadir))\n",
    "\n",
    "dataset = \"Baby\"\n",
    "download_data(dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 160792 data for dataset Baby\n"
     ]
    }
   ],
   "source": [
    "def  load_data (dataset_name, datadir):\n",
    "    filepath = os.path.join(datadir, 'reviews_%s_5.json' % dataset_name)\n",
    "    if not os.path.exists(filepath):\n",
    "        download_data(dataset_name, datadir)\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:                            # read file line by line\n",
    "            item_hash = hash(line)                # we will use this later for partitioning our data \n",
    "            item = json.loads(line)               # convert JSON string to Python dict\n",
    "            item['hash'] = item_hash              # add hash for identification purposes\n",
    "            data.append(item)\n",
    "    print(\"Loaded %d data for dataset %s\" % (len(data), dataset_name))\n",
    "    return data\n",
    "\n",
    "# load the data...\n",
    "baby = load_data(dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 96192 training examples, 32270 validation examples, and 32330 test examples\n"
     ]
    }
   ],
   "source": [
    "def partition_train_validation_test(data):\n",
    "    # 60% : modulus is 0, 1, 2, 3, 4, or 5\n",
    "    data_train = [item for item in data if item['hash']%10<=5]  \n",
    "    # 20% : modulus is 6 or 7\n",
    "    data_valid = [item for item in data if item['hash']%10 in [6,7]] \n",
    "    # 20% : modulus is 8 or 9\n",
    "    data_test  = [item for item in data if item['hash']%10 in [8,9]] \n",
    "    print(\"Now we have\", len(data_train), \"training examples,\", len(data_valid),\n",
    "      \"validation examples, and\", len(data_test), \"test examples\")\n",
    "    return data_train, data_valid, data_test\n",
    "    \n",
    "baby_train, baby_valid, baby_test = partition_train_validation_test(baby)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8571428571428571, 0.0)\n",
      "(0.0, 0.8571428571428571)\n"
     ]
    }
   ],
   "source": [
    "eng_stopwords = set(stopwords.words('english'))\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "def my_tokenize(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        #Adds to the array and array with the words in lowercase, we add them if they are not stopwords and there is at least one letter in it\n",
    "        tokens.extend(x for x in word_tokenize(sentence.lower()) #continues down...\n",
    "                      if x not in eng_stopwords and any(i.isalpha() for i in x))# This extends the list by adding elements, it is different from append... see https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python \n",
    "    return tokens\n",
    "\n",
    "def pos_neg_fraction(text): # We recieve the raw text\n",
    "    tokens = my_tokenize(text) # We tokenize the text first\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in positive_words:\n",
    "            count_pos += 1\n",
    "        if t in negative_words:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens) # this is because we need to be sure there is no 0 len sentence\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:\n",
    "        return 0., 0.\n",
    "    \n",
    "pos_example = 'This is a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example = 'This is a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction(pos_example))\n",
    "print(pos_neg_fraction(neg_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found a fraction of 100.000000 % positive words for example 5891\n",
      "{'reviewerID': 'AKU0ZZ3IEZW42', 'asin': 'B0001BUKA8', 'helpful': [0, 0], 'reviewText': 'useful peace', 'overall': 5.0, 'summary': 'Five Stars', 'unixReviewTime': 1405382400, 'reviewTime': '07 15, 2014', 'hash': -6617672656278504118}\n",
      "We found a fraction of 100.000000 % negative words for example 24754\n",
      "{'reviewerID': 'A1SLEYD29KEUW1', 'asin': 'B000WUD83O', 'reviewerName': 'ABDULLAH AL-FALAH', 'helpful': [0, 0], 'reviewText': 'too noisy', 'overall': 2.0, 'summary': 'Two Stars', 'unixReviewTime': 1404432000, 'reviewTime': '07 4, 2014', 'hash': 982920051594646061}\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_matrix(data):\n",
    "    # data is a lot of text in {} that has reviwer name..comment...date...etc.. but all identified with text labels\n",
    "    #in that sence data is an unidiminsional array\n",
    "    # the item \"atribute\", we added it to the data to identify the sections of it\n",
    "    return numpy.array([list(pos_neg_fraction(item['reviewText'])) for item in data])\n",
    "# X_train with two columns and as many rows as there are examples in the data set. \n",
    "#The first column contains the fraction of positive words, \n",
    "#while the second column contains the fraction of negative words for each example.\n",
    "X_train = dataset_to_matrix(baby_train)\n",
    "X_valid = dataset_to_matrix(baby_valid)\n",
    "X_test = dataset_to_matrix(baby_test)\n",
    "most_pos, most_neg = numpy.argmax(X_train, axis=0) # find maximum ROW (axis 0).. through aaaaallll the data (OMG!)\n",
    "# print the example with the highest fraction of positive words:\n",
    "print(\"We found a fraction of %f %% positive words for example %d\" % \n",
    "      (100.*X_train[most_pos, 0], most_pos))\n",
    "print(baby_train[most_pos])\n",
    "print(\"We found a fraction of %f %% negative words for example %d\" %\n",
    "      (100.*X_train[most_neg, 1], most_neg))\n",
    "print(baby_train[most_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our feature matrix is two-dimensional and has shape (96192, 2)\n",
      "Our target vector is one-dimensional and has shape (96192,)\n"
     ]
    }
   ],
   "source": [
    "def  dataset_to_targets (data):\n",
    "    return numpy.array([item['overall'] for item in data])\n",
    "\n",
    "Y_train = dataset_to_targets(baby_train)\n",
    "Y_valid = dataset_to_targets(baby_valid)\n",
    "Y_test = dataset_to_targets(baby_test)\n",
    "print(\"Our feature matrix is two-dimensional and has shape\", X_train.shape) # contains pos,neg fraction\n",
    "print(\"Our target vector is one-dimensional and has shape\", Y_train.shape) # containd sscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for the fpos variable is 3.182768559250442\n",
      "The coefficient for the fneg variable is -5.706641179286308\n",
      "The intercept is 4.019695273577839\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression().fit(X_train,Y_train)\n",
    "print(\"The coefficient for the fpos variable is\", lreg.coef_[0])\n",
    "print(\"The coefficient for the fneg variable is\", lreg.coef_[1])\n",
    "print(\"The intercept is\", lreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is 4.656249 stars\n",
      "This is the same as 4.656249 stars\n",
      "The expected rating is 2.878367 stars\n",
      "This is the same as 2.878367 stars\n"
     ]
    }
   ],
   "source": [
    "#If the review contains 20% positive words (fpos==0.2) \n",
    "#but still no negative words (fneg==0), we would expect the following rating:\n",
    "features = [[0.2, 0]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0.2*lreg.coef_[0] + 0*lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)\n",
    "#However, if the review contains no positive words (fpos==0) but 20% negative words (fneg==0.2),\n",
    "#we expect the following rating:\n",
    "features = [[0, 0.2]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0 * lreg.coef_[0] + 0.2 * lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lreg(features):\n",
    "    expected_rating = lreg.predict(features)\n",
    "    expected_rating[expected_rating > 5.0] = 5.0\n",
    "    expected_rating[expected_rating < 1.0] = 1.0\n",
    "    return expected_rating\n",
    "\n",
    "pred_train = predict_lreg(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training data is 0.828969 stars\n"
     ]
    }
   ],
   "source": [
    "mae_train = mean_absolute_error(pred_train, Y_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" % mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - calculate the prediction for 100% pos, and 100% neg review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating for 100 pos review is 7.202464 stars\n",
      "The expected rating  for 100 neg review is -1.686946 stars\n"
     ]
    }
   ],
   "source": [
    "features_100pos=[[1,0]]\n",
    "features_100neg=[[0,1]]\n",
    "expected_rating_pos = lreg.predict(features_100pos)[0] # I think 0 is for linear as in kernel = {‘linear’, ‘rbf’, ‘poly’, ‘sigmoid’, ‘precomputed’}\n",
    "expected_rating_neg = lreg.predict(features_100neg)[0]\n",
    "print(\"The expected rating for 100 pos review is %f stars\" % expected_rating_pos)\n",
    "print(\"The expected rating  for 100 neg review is %f stars\" % expected_rating_neg)\n",
    "# This model needs a threshold to limit the starts between 0 and 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Repeat this same process for \"Apps for Android\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Apps_for_Android has already been downloaded to ./data/\n"
     ]
    }
   ],
   "source": [
    "###### Getting data####\n",
    "android_dataset = \"Apps_for_Android\"\n",
    "download_data(android_dataset, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 752937 data for dataset Apps_for_Android\n",
      "Now we have 451384 training examples, 151060 validation examples, and 150493 test examples\n",
      "{'reviewerID': 'AWUDE6LOH5Y2Q', 'asin': 'B004DLPXAO', 'reviewerName': 'Amazon Customer', 'helpful': [0, 0], 'reviewText': 'Love it!', 'overall': 5.0, 'summary': 'Take you Kindle Library along whenever you have your phone!', 'unixReviewTime': 1404691200, 'reviewTime': '07 7, 2014', 'hash': 95567176886258644}\n",
      "\n",
      "{'reviewerID': 'AK60UXMNOQNFJ', 'asin': 'B004JK61K0', 'helpful': [0, 0], 'reviewText': 'Stupid and pointless', 'overall': 1.0, 'summary': 'One Star', 'unixReviewTime': 1405382400, 'reviewTime': '07 15, 2014', 'hash': 5413378431462987772}\n"
     ]
    }
   ],
   "source": [
    "################Processing data############\n",
    "# Load data from directory\n",
    "apps= load_data(android_dataset,datadir)\n",
    "#Partition data for training validation and tests\n",
    "apps_train,apps_valid,apps_test = partition_train_validation_test(apps)\n",
    "#We get the portions of positive and negative terms, omiting stopwords and puntuation marks (tokenizing words and sentences as well))\n",
    "X_apps_train = dataset_to_matrix(apps_train)\n",
    "app_most_pos, app_most_neg = numpy.argmax(X_apps_train, axis=0)\n",
    "print(apps_train[app_most_pos])\n",
    "print()\n",
    "print(apps_train[app_most_neg])\n",
    "Y_apps_train = dataset_to_targets(apps_train) # extract the overall item from each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating for a review with 20 porcet positive comments is 4.656249 stars\n",
      "The expected rating for a review with 20 porcet negative comments is 2.878367 stars\n"
     ]
    }
   ],
   "source": [
    "####Linear regression\n",
    "lreg_app = LinearRegression().fit(X_apps_train, Y_apps_train)\n",
    "app_pos_features = [[0.2, 0]]\n",
    "app_neg_features = [[0,0.2]]\n",
    "expected_rating_pos = lreg.predict(app_pos_features)[0]\n",
    "expected_rating_neg= lreg.predict(app_neg_features)[0]\n",
    "print(\"The expected rating for a review with 20 porcet positive comments is %f stars\" % expected_rating_pos)\n",
    "print(\"The expected rating for a review with 20 porcet negative comments is %f stars\" % expected_rating_neg)\n",
    "#With this data we get sort of a similiar approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training data is 0.942205 stars\n"
     ]
    }
   ],
   "source": [
    "pred_train_apps = predict_lreg(X_apps_train)\n",
    "mae_train_apps = mean_absolute_error(pred_train_apps, Y_apps_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" % mae_train_apps)\n",
    "#We are getting even a higher error with a much more bigger dataset, funny, because it is bigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data contains 21.302187 % dissatisfied customers\n",
      "[False False False False False  True False False False False]\n"
     ]
    }
   ],
   "source": [
    "def discretize_targets(Y):\n",
    "    return Y<= 3.0 # So this is a boolean, we are returning if the conditions is true\n",
    "D_train = discretize_targets(Y_train) # We must remember that Y_train is a 1 dimension array with the scores\n",
    "print(\"The training data contains %f %% dissatisfied customers\" % (100.*D_train.mean()))\n",
    "print(D_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example number 24754\n",
      "True rating = 2.000000 stars\n",
      "Expected to be dissatisfied: True\n",
      "Expected probability of being dissatisfied : 0.999866\n",
      "Features = 0.000000 / 1.000000\n",
      "Review text = too noisy\n",
      "\n",
      "Training example number 5891\n",
      "True rating = 5.000000 stars\n",
      "Expected to be dissatisfied: False\n",
      "Expected probability of being dissatisfied : 0.000034\n",
      "Features = 1.000000 / 0.000000\n",
      "Review text = useful peace\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train, D_train) # We use just the training data\n",
    "# The predict_proba() method produces a matrix with two columns\n",
    "# the first column contains the probability for the label being \"false\" (satisfied customer)\n",
    "# the second column contains the probability for the label being \"true\" (dissatisfied customer)\n",
    "# the sum of both columns is 1\n",
    "# we select the second column with [:,1]\n",
    "# [:,0] would select the first column\n",
    "# [1,:] would select the second row\n",
    "prob2_train = logreg.predict_proba(X_train)[:,1]\n",
    "pred2_train = prob2_train > 0.5\n",
    "max_prob2 = numpy.argmax(prob2_train)\n",
    "min_prob2 = numpy.argmin(prob2_train)\n",
    "def analyze_training_example_2(i):\n",
    "    print(\"Training example number\", i)\n",
    "    print(\"True rating = %f stars\" % Y_train[i])\n",
    "    print(\"Expected to be dissatisfied:\", pred2_train[i])\n",
    "    print(\"Expected probability of being dissatisfied : %f\" % prob2_train[i])\n",
    "    print(\"Features = %f / %f\" % (X_train[i,0], X_train[i,1]))\n",
    "    print(\"Review text = %s\" % baby_train[i]['reviewText'])\n",
    "    \n",
    "analyze_training_example_2(max_prob2)\n",
    "print()\n",
    "analyze_training_example_2(min_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the default threshold (0.5) we get precision = 0.600492 and recall = 0.095359\n"
     ]
    }
   ],
   "source": [
    "precision2 = precision_score(D_train, pred2_train)\n",
    "recall2 = recall_score(D_train, pred2_train)\n",
    "print(\"For the default threshold (0.5) we get precision = %f \"\n",
    "      \"and recall = %f\" % (precision2, recall2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the precision is 0.484644 and the recall is 0.157874\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB().fit(X_train, D_train)\n",
    "prob3_train = nb.predict_proba(X_train)[:,1]\n",
    "pred3_train = prob3_train>0.5\n",
    "precision3 = precision_score(D_train, pred3_train)\n",
    "recall3 = recall_score(D_train, pred3_train)\n",
    "print(\"Now the precision is %f and the recall is %f\" % (precision3, recall3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Change the treshold from 0.5 to 0.2, and rerun the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the default threshold (0.2) we get precision = 0.321801 and recall = 0.735786\n"
     ]
    }
   ],
   "source": [
    "new_pred2_train = prob2_train > 0.2\n",
    "new_precision = precision_score(D_train, new_pred2_train)\n",
    "new_recall =  recall_score(D_train, new_pred2_train)\n",
    "print(\"For the default threshold (0.2) we get precision = %f \"\n",
    "      \"and recall = %f\" % (new_precision, new_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Give a commentary in plain English about how that changed precision and recall. What does that mean? What is now included that wasn't before? What part of it is good? What is bad from our Task perspective. Remember: our task was to identify Dissatisfied reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is droping because we are taking more cases as valid (dissatisfied costumers) as our threshold is lower, however there are more chances that a higher proportion of cases labaled as \"dissatisfied\" where actually sattisfied. From our problem perspective I think it is better to encrease the recall as I guess we are more interested in identifiying dissatisfied costumers to address the product's problems ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\MAGUIL~1\\AppData\\Local\\Temp\\tmp30ll65ys\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\MAGUIL~1\\\\AppData\\\\Local\\\\Temp\\\\tmp30ll65ys', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000234A8CD1390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\MAGUIL~1\\AppData\\Local\\Temp\\tmp30ll65ys\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2454.0, step = 0\n",
      "INFO:tensorflow:global_step/sec: 427.594\n",
      "INFO:tensorflow:loss = 265.41595, step = 100 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 555.876\n",
      "INFO:tensorflow:loss = 162.88437, step = 200 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.145\n",
      "INFO:tensorflow:loss = 171.59747, step = 300 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.043\n",
      "INFO:tensorflow:loss = 157.54922, step = 400 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 578.374\n",
      "INFO:tensorflow:loss = 220.74158, step = 500 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.406\n",
      "INFO:tensorflow:loss = 151.72397, step = 600 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.474\n",
      "INFO:tensorflow:loss = 141.01819, step = 700 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.051\n",
      "INFO:tensorflow:loss = 127.66345, step = 800 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.854\n",
      "INFO:tensorflow:loss = 174.97067, step = 900 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.854\n",
      "INFO:tensorflow:loss = 125.27018, step = 1000 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.01\n",
      "INFO:tensorflow:loss = 121.2184, step = 1100 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.672\n",
      "INFO:tensorflow:loss = 179.4856, step = 1200 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.695\n",
      "INFO:tensorflow:loss = 134.71461, step = 1300 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.641\n",
      "INFO:tensorflow:loss = 141.14594, step = 1400 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.458\n",
      "INFO:tensorflow:loss = 182.77463, step = 1500 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.852\n",
      "INFO:tensorflow:loss = 163.33281, step = 1600 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.854\n",
      "INFO:tensorflow:loss = 138.89082, step = 1700 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.913\n",
      "INFO:tensorflow:loss = 212.19647, step = 1800 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.142\n",
      "INFO:tensorflow:loss = 125.064896, step = 1900 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.475\n",
      "INFO:tensorflow:loss = 148.11253, step = 2000 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.472\n",
      "INFO:tensorflow:loss = 117.39152, step = 2100 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.452\n",
      "INFO:tensorflow:loss = 160.10487, step = 2200 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 794.111\n",
      "INFO:tensorflow:loss = 167.40611, step = 2300 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.795\n",
      "INFO:tensorflow:loss = 138.04523, step = 2400 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.603\n",
      "INFO:tensorflow:loss = 121.47879, step = 2500 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.892\n",
      "INFO:tensorflow:loss = 122.86948, step = 2600 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.913\n",
      "INFO:tensorflow:loss = 151.24678, step = 2700 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.915\n",
      "INFO:tensorflow:loss = 144.09637, step = 2800 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.474\n",
      "INFO:tensorflow:loss = 120.271614, step = 2900 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.009\n",
      "INFO:tensorflow:loss = 166.14777, step = 3000 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.697\n",
      "INFO:tensorflow:loss = 121.79651, step = 3100 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.695\n",
      "INFO:tensorflow:loss = 100.73274, step = 3200 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.312\n",
      "INFO:tensorflow:loss = 187.74007, step = 3300 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.051\n",
      "INFO:tensorflow:loss = 155.79637, step = 3400 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.14\n",
      "INFO:tensorflow:loss = 130.68488, step = 3500 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.013\n",
      "INFO:tensorflow:loss = 142.21024, step = 3600 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.622\n",
      "INFO:tensorflow:loss = 167.12772, step = 3700 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.663\n",
      "INFO:tensorflow:loss = 178.61276, step = 3800 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.719\n",
      "INFO:tensorflow:loss = 115.95886, step = 3900 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.672\n",
      "INFO:tensorflow:loss = 145.2806, step = 4000 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 794.104\n",
      "INFO:tensorflow:loss = 151.03192, step = 4100 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.479\n",
      "INFO:tensorflow:loss = 212.12314, step = 4200 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.852\n",
      "INFO:tensorflow:loss = 178.87181, step = 4300 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.456\n",
      "INFO:tensorflow:loss = 102.63286, step = 4400 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.913\n",
      "INFO:tensorflow:loss = 138.52995, step = 4500 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.469\n",
      "INFO:tensorflow:loss = 132.07413, step = 4600 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.855\n",
      "INFO:tensorflow:loss = 150.21869, step = 4700 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.14\n",
      "INFO:tensorflow:loss = 131.76498, step = 4800 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.349\n",
      "INFO:tensorflow:loss = 150.5789, step = 4900 (0.138 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\MAGUIL~1\\AppData\\Local\\Temp\\tmp30ll65ys\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 158.97076.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x234a8cd1080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols = [tf.feature_column.numeric_column(key=\"fpos\"),\n",
    "             tf.feature_column.numeric_column(key=\"fneg\")]\n",
    "model = tf.estimator.LinearRegressor(feature_columns=feat_cols)\n",
    "get_training_data = tf.estimator.inputs.numpy_input_fn(\n",
    "                     x={\"fpos\" : X_train[:,0], \"fneg\" : X_train[:,1]},\n",
    "                     y=Y_train, num_epochs=None, shuffle=True)\n",
    "\n",
    "model.train(input_fn=get_training_data, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MAGUIL~1\\AppData\\Local\\Temp\\tmp30ll65ys\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "The mean absolute error on the training data is 0.843495 stars\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_training_data = tf.estimator.inputs.numpy_input_fn(\n",
    "                     x={\"fpos\":X_train[:,0], \"fneg\": X_train[:,1]},\n",
    "                     num_epochs=1, shuffle=False)\n",
    "pred_train_tf = numpy.array([item['predictions'][0] for item in \n",
    "                         model.predict(input_fn=eval_training_data)])\n",
    "mae_train_tf = mean_absolute_error(pred_train_tf, Y_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" \n",
    "      % mae_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence = This product wasn't bad.\n",
      "['this', 'product', 'was', \"n't\", 'bad_NEG', '.']\n",
      "Sentence = This is not a bad product.\n",
      "['this', 'is', 'not', 'a_NEG', 'bad_NEG', 'product_NEG', '.']\n",
      "Sentence = This product was bad.\n",
      "['this', 'product', 'was', 'bad', '.']\n",
      "Sentence = This is a bad product.\n",
      "['this', 'is', 'a', 'bad', 'product', '.']\n",
      "Perfect way to keep track of the day for a little one-- this journal allows for detailed tracking of milk intake, diapers, sleep, and activity. Highly recommended as a perfect way to keep track and organize information in one easy to travel with place!\n",
      "['perfect', 'way', 'keep', 'track', 'day', 'little', 'one', 'journal', 'allows', 'detailed', 'tracking', 'milk', 'intake', 'diapers', 'sleep', 'activity', 'highly', 'recommended', 'perfect', 'way', 'keep', 'track', 'organize', 'information', 'one', 'easy', 'travel', 'place']\n"
     ]
    }
   ],
   "source": [
    "examples_negation = [\"This product wasn't bad.\",\n",
    "                     \"This is not a bad product.\",\n",
    "                     \"This product was bad.\",\n",
    "                     \"This is a bad product.\"]\n",
    "\n",
    "for sentence in examples_negation:\n",
    "    tokens_with_negation = mark_negation(word_tokenize(sentence.lower())) # Append _NEG suffix to words that appear in the scope between a negation and a punctuation mark.\n",
    "    print(\"Sentence =\", sentence)\n",
    "    print(tokens_with_negation)\n",
    "\n",
    "negated_stopwords = set(x+\"_NEG\" for x in eng_stopwords)\n",
    "all_stopwords = eng_stopwords.union(negated_stopwords)   # set union stopwords and negate stopwords\n",
    "    \n",
    "def tokenize_with_negation(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        pretokens = word_tokenize(sentence.lower())\n",
    "        pretokens = [x for x in pretokens if any(i.isalpha() for i in x)] #Everything the same unitl here\n",
    "        #Append _NEG suffix to words that appear in the scope between a negation \n",
    "        #and a punctuation mark\n",
    "        pretokens = mark_negation(pretokens) #Here\n",
    "        # ok, but tokens started empy so we are bsically storing the array\n",
    "        tokens.extend(x for x in pretokens if x not in all_stopwords) # puts a list at the beegining of the frist list\n",
    "    return tokens\n",
    "\n",
    "print(baby_train[31]['reviewText'])\n",
    "print(tokenize_with_negation(baby_train[31]['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8571428571428571, 0.0)\n",
      "(0.0, 0.8571428571428571)\n",
      "(0.0, 0.8571428571428571)\n",
      "(0.8571428571428571, 0.0)\n"
     ]
    }
   ],
   "source": [
    "all_positive_words = positive_words.union({x+\"_NEG\" for x in negative_words})\n",
    "all_negative_words = negative_words.union({x+\"_NEG\" for x in positive_words})\n",
    "def pos_neg_fraction_with_negation(text):\n",
    "    tokens = tokenize_with_negation(text) #Tokenize and adds negation when necessary\n",
    "    # count how many positive and negative words occur in the text\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in all_positive_words:\n",
    "            count_pos += 1\n",
    "        if t in all_negative_words:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens)\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:  # avoid division by zero\n",
    "        return 0., 0.\n",
    "    \n",
    "pos_example = 'This is a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example = 'This is a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction_with_negation(pos_example))\n",
    "print(pos_neg_fraction_with_negation(neg_example))\n",
    "pos_example_neg = 'This is not a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example_neg = 'This is not a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction_with_negation(pos_example_neg))\n",
    "print(pos_neg_fraction_with_negation(neg_example_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_matrix_with_neg(data):\n",
    "    return numpy.array([list(pos_neg_fraction_with_negation(item['reviewText'])) for item in data])\n",
    "\n",
    "X_train_neg = dataset_to_matrix_with_neg(baby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.812961 stars\n"
     ]
    }
   ],
   "source": [
    "lreg_neg = LinearRegression().fit(X_train_neg, Y_train)\n",
    "pred_train_neg = lreg_neg.predict(X_train_neg)\n",
    "mae_train_with_neg = mean_absolute_error(pred_train_neg, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f stars\" % mae_train_with_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maguileracanon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A nonlinear regressor achieves a MAE of 0.712048 stars\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_neg = RandomForestRegressor().fit(X_train_neg,Y_train)\n",
    "pred_train_rf_neg = rf_neg.predict(X_train_neg)\n",
    "mae_train_rf_neg = mean_absolute_error(pred_train_rf_neg, Y_train)\n",
    "print(\"A nonlinear regressor achieves a MAE of %f stars\" % mae_train_rf_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add features , Explain which features you chose, implement them, and write a commentary on your results... Feel welcome to use NLTK's built-in sentiment analyzer or any other research that you can find and understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add emojis (personal choice, I communicate with emojis the whole time), also if a word is in uupercases then it will count as 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_negation_Emojis(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    tknzr = TweetTokenizer()\n",
    "    for sentence in sent_tokenize(text):\n",
    "        #pretokens = word_tokenize(sentence.lower())\n",
    "        emopretokens = tknzr.tokenize(sentence) #use tweet tokenizer to include emojis\n",
    "        emojis  = [x for x in emopretokens if x in SAD or x in HAPPY]\n",
    "        # if a word is in uppercase then count ir twice \n",
    "        pretokens_emphasis = [x for x in emopretokens if x.isupper() and x.isalpha()]\n",
    "        pretokens = word_tokenize(sentence.lower())\n",
    "        pretokens = [x for x in pretokens if any(i.isalpha() for i in x)] #Everything the same unitl here\n",
    "        #Append _NEG suffix to words that appear in the scope between a negation \n",
    "        #and a punctuation mark\n",
    "        pretokens.extend(pretokens_emphasis)\n",
    "        pretokens = mark_negation(pretokens) #Here\n",
    "        pretokens.extend(emojis)\n",
    "        # ok, but tokens started empy so we are bsically storing the array\n",
    "        tokens.extend(x for x in pretokens if x not in all_stopwords) # puts a list at the beegining of the frist list\n",
    "    return tokens\n",
    "\n",
    "all_positive_words_emoji = all_positive_words.union(HAPPY)\n",
    "all_negative_words_emoji = all_negative_words.union(SAD)\n",
    "\n",
    "def pos_neg_fraction_with_negation_emoji(text):\n",
    "    tokens = tokenize_with_negation_Emojis(text) #Tokenize and adds negation when necessary\n",
    "    # count how many positive and negative words occur in the text\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in all_positive_words_emoji:\n",
    "            count_pos += 1\n",
    "        if t in all_negative_words_emoji:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens)\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:  # avoid division by zero\n",
    "        return 0., 0.\n",
    "def dataset_to_matrix_with_neg_emoji(data):\n",
    "    return numpy.array([list(pos_neg_fraction_with_negation_emoji(item['reviewText'])) for item in data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.0)\n",
      "(0.0, 1.0)\n",
      "This is a good solid dressing table.  We received it because my in-laws found it at a consignment shop, so I can't comment about other reviewers' concerns regarding assembly.  The table serves the purpose and is a good value for those who don't want to spend a lot of money on a dressing table.  We didn't feel that we needed a fancy dressing table and instead opted to purchase a more expensive crib, which is really the focal point of the nursery.  The dressing table has two shelves that are quite convenient for holding supplies.  I placed baskets on those shelves to hold diapers, etc.\n",
      "(0.1016949152542373, 0.01694915254237288)\n"
     ]
    }
   ],
   "source": [
    "my_example =\" :D :) ;) \"\n",
    "print(pos_neg_fraction_with_negation_emoji(my_example))\n",
    "my_example = \":( :/)\"\n",
    "print(pos_neg_fraction_with_negation_emoji(my_example))\n",
    "print(baby_train[700]['reviewText'])\n",
    "print(pos_neg_fraction_with_negation_emoji(baby_train[700]['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_neg_emoji = dataset_to_matrix_with_neg_emoji(baby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.813013 stars\n"
     ]
    }
   ],
   "source": [
    "lreg_neg_emoji = LinearRegression().fit(X_train_neg_emoji, Y_train)\n",
    "pred_train_neg_emoji = lreg_neg_emoji.predict(X_train_neg_emoji)\n",
    "mae_train_with_neg_emoji = mean_absolute_error(pred_train_neg_emoji, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f stars\" % mae_train_with_neg_emoji)\n",
    "# I managed to improve the model a littttllleee bit :P 0.813530 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'HUGE', '!', '!', ':D']\n",
      "['this', 'is', 'HUGE', '!', '!', ':', 'D']\n"
     ]
    }
   ],
   "source": [
    "#Diferences between the tokenizers\n",
    "print(TweetTokenizer().tokenize(\"this is HUGE!! :D \"))\n",
    "print(word_tokenize(\"this is HUGE!! :D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought this based on the great reviews but my son wasn't that into it.\n",
      "{'neg': 0.0, 'neu': 0.836, 'pos': 0.164, 'compound': 0.3716}\n",
      "Definitely not worth the price.\n",
      "{'neg': 0.226, 'neu': 0.407, 'pos': 0.367, 'compound': 0.2579}\n"
     ]
    }
   ],
   "source": [
    "sia= SentimentIntensityAnalyzer()\n",
    "text = baby_train[50000]['reviewText']\n",
    "for s in sent_tokenize(text):\n",
    "    print(s)\n",
    "    print(sia.polarity_scores(s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sia_features(dataset):\n",
    "    '''\n",
    "    For each review text in the dataset, extract: \n",
    "    (1) mean positive sentiment over all sentences\n",
    "    (2) mean neutral sentiment over all sentences\n",
    "    (3) mean negative sentiment over all  sentences\n",
    "    (4) maximum postive sentiment over all sentences\n",
    "    (5) maximum neutral sentiment over all sentences\n",
    "    (6) maximum negative sentiment over al sentences \n",
    "'''\n",
    "    feat_matrix = numpy.empty((len(dataset),6))\n",
    "    for i in range(len(dataset)):\n",
    "        sentences = sent_tokenize(dataset[i]['reviewText'])\n",
    "        nsent = len(sentences)\n",
    "        if nsent:\n",
    "            sentences_polarities = numpy.empty((nsent,3))\n",
    "            for j in range(nsent):\n",
    "                polarity = sia.polarity_scores(sentences[j])\n",
    "                sentences_polarities[j,0] = polarity['pos']\n",
    "                sentences_polarities[j,1] = polarity['neu']\n",
    "                sentences_polarities[j,2] = polarity['neg']\n",
    "            feat_matrix[i, 0:3] = numpy.mean(sentences_polarities, axis = 0) #axis 0 is row, axis 1 is columns\n",
    "            feat_matrix[i,3:6] = numpy.max(sentences_polarities, axis = 0)\n",
    "        else:\n",
    "            feat_matrix[i, 0:6] = 0.0\n",
    "            \n",
    "    return feat_matrix\n",
    "            \n",
    "sia_tr = sia_features(baby_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Homework** : add lenght function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_train[1000]['reviewText'][6] == \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.246 0.   ]\n"
     ]
    }
   ],
   "source": [
    "def len_features(dataset):\n",
    "    '''\n",
    "    Add two features:\n",
    "    (1) lenght of review (in thousands of characters) - truncate at 2500\n",
    "    (2) percengate of exclamation marks (in %)    \n",
    "    '''\n",
    "    lenfeat_matrix =  numpy.empty((len(dataset),2))\n",
    "    for i in range(len(dataset)):\n",
    "        excla = 0\n",
    "        review= dataset[i]['reviewText']\n",
    "        for j in range(len(review)):\n",
    "            if(j < 2500000) :\n",
    "                if review[j] == \"!\":\n",
    "                    excla = excla +1 \n",
    "        \n",
    "        review_len = (len(dataset[i]['reviewText']))/1000 \n",
    "        if (review_len >= 2500):\n",
    "            review_len = 2500\n",
    "            \n",
    "        if(review_len==0):\n",
    "            excla_percentage =0\n",
    "        else:\n",
    "            excla_percentage = excla/(review_len*1000)\n",
    "\n",
    "        lenfeat_matrix[i,0] = review_len\n",
    "        lenfeat_matrix[i,1] = excla_percentage  *100        \n",
    "            \n",
    "    return lenfeat_matrix      \n",
    "len_tr = len_features(baby_train)\n",
    "print(len_tr[800, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96192, 2) (96192, 6) (96192, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_neg.shape, sia_tr.shape , len_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.755603 starts\n"
     ]
    }
   ],
   "source": [
    "# stack horizontally \n",
    "X_train_augmented = numpy.concatenate(( X_train_neg, sia_tr) ,axis = 1)\n",
    "lreg_augmented = LinearRegression().fit(X_train_augmented,Y_train)\n",
    "pred_train_augmented = lreg_augmented.predict(X_train_augmented)\n",
    "mean_train_augmented = mean_absolute_error(pred_train_augmented, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f starts\" % mean_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.755067 starts\n"
     ]
    }
   ],
   "source": [
    "#Now with the lenght and exclamation % feature\n",
    "X_train_augmented2 = numpy.concatenate(( X_train_neg, sia_tr, len_tr) ,axis = 1)\n",
    "lreg_augmented2 = LinearRegression().fit(X_train_augmented2,Y_train)\n",
    "pred_train_augmented2 = lreg_augmented2.predict(X_train_augmented2)\n",
    "mean_train_augmented2 = mean_absolute_error(pred_train_augmented2, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f starts\" % mean_train_augmented2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the RF, MAE is 0.291753 stars\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rf_augmented = RandomForestRegressor().fit(X_train_augmented, Y_train) #fetting\n",
    "rfpred_train_augmented = rf_augmented.predict(X_train_augmented) # prediction\n",
    "mae_train_rf_augmented = mean_absolute_error(rfpred_train_augmented, Y_train) #check error\n",
    "print(\"For the RF, MAE is %f stars\" % mae_train_rf_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the RF, MAE is 0.291753 stars\n"
     ]
    }
   ],
   "source": [
    "# random forest NOW with the len_ft matrix\n",
    "rf_augmented2 = RandomForestRegressor().fit(X_train_augmented2, Y_train) #fetting\n",
    "rfpred_train_augmented2 = rf_augmented2.predict(X_train_augmented2) # prediction\n",
    "mae_train_rf_augmented2 = mean_absolute_error(rfpred_train_augmented2, Y_train) #check error\n",
    "print(\"For the RF, MAE is %f stars\" % mae_train_rf_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on the validation set, we get 0.767952 error for the linear regresion\n",
      "and 0.762587  for the random forest regresion\n"
     ]
    }
   ],
   "source": [
    "X_valid_neg = dataset_to_matrix(baby_valid)\n",
    "sia_valid = sia_features(baby_valid)\n",
    "#leng_valid\n",
    "X_valid_augmented = numpy.concatenate((X_valid_neg,sia_valid), axis = 1)\n",
    "pred_valid_lraugmented = lreg_augmented.predict(X_valid_augmented)\n",
    "pred_valid_rf_augmented = rf_augmented.predict(X_valid_augmented)\n",
    "\n",
    "mae_valid_augmented = mean_absolute_error(pred_valid_lraugmented, Y_valid)\n",
    "print(\"on the validation set, we get %f error for the linear regresion\" % mae_valid_augmented)\n",
    "mae_valid_rfaugemented = mean_absolute_error(pred_valid_rf_augmented, Y_valid)\n",
    "print(\"and %f  for the random forest regresion\" % mae_valid_rfaugemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HOMEWORK**  =\"Be lazy. Not just lazy but proactively, agressively lazy.\" Remove duplication.\n",
    "create a single function that takes in data and spits out all success metrics across all of your algos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.755067 starts\n",
      "For the RF, MAE is 0.280793 stars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7550668260507329, 0.28079257379255756)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def WholeAnalysisPipeline(data): # works for train or validation data\n",
    "\n",
    "    Y_data = dataset_to_targets(data)\n",
    "\n",
    "    whole_feat_matrix = numpy.empty((len(data),10)) # all the features in just one \n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        pos_neg_matrix = numpy.empty((len(data),2))\n",
    "        excla = 0\n",
    "        review= data[i]['reviewText']\n",
    "        whole_feat_matrix[i,0:2] = pos_neg_fraction_with_negation(review)\n",
    "        \n",
    "        #From sia\n",
    "        sentences = sent_tokenize(review)\n",
    "        nsent = len(sentences)\n",
    "        if nsent:\n",
    "            sentences_polarities = numpy.empty((nsent,3))\n",
    "            for j in range(nsent):\n",
    "                polarity = sia.polarity_scores(sentences[j])\n",
    "                sentences_polarities[j,0] = polarity['pos']\n",
    "                sentences_polarities[j,1] = polarity['neu']\n",
    "                sentences_polarities[j,2] = polarity['neg']\n",
    "            whole_feat_matrix[i, 2:5] = numpy.mean(sentences_polarities, axis = 0) #axis 0 is row, axis 1 is columns\n",
    "            whole_feat_matrix[i,5:8] = numpy.max(sentences_polarities, axis = 0)\n",
    "        else:\n",
    "            whole_feat_matrix[i, 2:8] = 0.0\n",
    "        \n",
    "        #from len\n",
    "        for j in range(len(review)):\n",
    "            if(j < 2500000) :\n",
    "                if review[j] == \"!\":\n",
    "                    excla = excla +1 \n",
    "        \n",
    "        review_len = (len(data[i]['reviewText']))/1000 \n",
    "        if (review_len >= 2500):\n",
    "            review_len = 2500\n",
    "            \n",
    "        if(review_len==0):\n",
    "            excla_percentage =0\n",
    "        else:\n",
    "            excla_percentage = excla/(review_len*1000)\n",
    "\n",
    "        whole_feat_matrix[i,8] = review_len\n",
    "        whole_feat_matrix[i,9] = excla_percentage  *100        \n",
    "\n",
    "        \n",
    "    m_lreg_augmented = LinearRegression().fit(whole_feat_matrix,Y_data)\n",
    "    m_pred_train_augmented = m_lreg_augmented.predict(whole_feat_matrix)\n",
    "    m_mean_train_augmented2 = mean_absolute_error(m_pred_train_augmented, Y_data)\n",
    "    print(\"Now the mean absolute error on the training data is %f starts\" % m_mean_train_augmented2)\n",
    "    m_rf_augmented = RandomForestRegressor().fit(whole_feat_matrix, Y_data) #fetting\n",
    "    m_rfpred_train_augmented = m_rf_augmented.predict(X_train_augmented2) # prediction\n",
    "    m_mae_train_rf_augmented = mean_absolute_error(m_rfpred_train_augmented, Y_data) #check error\n",
    "\n",
    "    print(\"For the RF, MAE is %f stars\" % m_mae_train_rf_augmented)\n",
    "    \n",
    "    return  m_mean_train_augmented2, m_mae_train_rf_augmented \n",
    "\n",
    "WholeAnalysisPipeline(baby_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
